{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This session will focus on model selection (cross validation and hyperparameter search) and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "from six.moves import urllib\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "fetch_housing_data()\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "housing = load_housing_data()\n",
    "#housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from CategoricalEncoder import CategoricalEncoder\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6 #manually input column\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "    \n",
    "# splite the data base on income_catalog distribution\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_num = housing.drop('ocean_proximity',axis=1)\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('cat_encoder', CategoricalEncoder(encoding=\"onehot-dense\")),\n",
    "    ])\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start from here, we have had our data prepared. Now we want to test and evaluate different model, and search for best hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# hyperparameters search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "lnr = LinearRegression()\n",
    "lnr.fit(housing_prepared,housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 203682.37379543  326371.39370781  204218.64588245   58685.4770482\n",
      "  194213.06443039  156914.96268363  424903.23204361  228174.06586255\n",
      "  140064.30950574   29195.73627083]\n",
      "[ 286600.  340600.  196900.   46300.  254500.  127900.  500001.  140200.\n",
      "   95000.  500001.]\n",
      "train set mean_square_error 68376.64\n"
     ]
    }
   ],
   "source": [
    "# See the prediction of train set and test set\n",
    "train_sample = housing.iloc[:10]\n",
    "train_lable = housing_labels.iloc[:10]\n",
    "train_sample_pre = full_pipeline.transform(train_sample) #we used \"trained\" transform, no need to fit\n",
    "train_sample_predict = lnr.predict(train_sample_pre)\n",
    "print (train_sample_predict)\n",
    "print (train_lable.values)\n",
    "lnr_mse = mean_squared_error(housing_labels,lnr.predict(housing_prepared))\n",
    "print ('train set mean_square_error {:.2f}'.format(np.sqrt(lnr_mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set mean_square_error 66741.36\n"
     ]
    }
   ],
   "source": [
    "housing_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "housing_test_labels = strat_test_set[\"median_house_value\"].copy() \n",
    "housing_test = full_pipeline.transform(housing_test)\n",
    "lnr_mse = mean_squared_error(housing_test_labels,lnr.predict(housing_test))\n",
    "print ('train set mean_square_error {:.2f}'.format(np.sqrt(lnr_mse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So obviously our model is underfitting due to both high error in trainset and testset given that our std for labels is 115k approximatly half of std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     16512.000000\n",
       "mean     206990.920724\n",
       "std      115703.014830\n",
       "min       14999.000000\n",
       "25%      119800.000000\n",
       "50%      179500.000000\n",
       "75%      263900.000000\n",
       "max      500001.000000\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree train set mean_square_error 0.00\n",
      "decision tree test set mean_square_error 70168.74\n"
     ]
    }
   ],
   "source": [
    "#try DecisionTreeRegression\n",
    "dtree = DecisionTreeRegressor()\n",
    "dtree.fit(housing_prepared,housing_labels)\n",
    "housing_test_pred = dtree.predict(housing_test)\n",
    "housing_train_prd = dtree.predict(housing_prepared)\n",
    "dtree_train_err = np.sqrt(mean_squared_error(housing_labels,housing_labels))\n",
    "dtree_test_err = np.sqrt(mean_squared_error(housing_test_labels,housing_test_pred))\n",
    "print ('decision tree train set mean_square_error {:.2f}'.format(dtree_train_err))\n",
    "print ('decision tree test set mean_square_error {:.2f}'.format(dtree_test_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn out to be overfitting (low train set error, high test set error). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ -4.52159158e+09  -4.34488577e+09  -5.10842088e+09  -4.66499259e+09\n",
      "  -5.02653153e+09  -5.67035514e+09  -5.11975168e+09  -5.05581964e+09\n",
      "  -5.75428373e+09  -4.73117906e+09]\n",
      "Mean: -4999781160.88\n",
      "Standard deviation: 434830854.074\n",
      "[ 67242.78089402  65915.74750796  71473.21794053  68300.75101619\n",
      "  70898.0361276   75301.76054978  71552.44008795  71104.28710438\n",
      "  75856.99523942  68783.56680332]\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "scores_tree = cross_val_score(dtree, housing_prepared, housing_labels,\n",
    "                        scoring='neg_mean_squared_error', cv=10)\n",
    "rmse_scores = np.sqrt(-scores_tree)\n",
    "display_scores(scores_tree)\n",
    "print (rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22112.540875989125"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "forest_reg.fit(housing_prepared, housing_labels)\n",
    "## making training error (generalized error)\n",
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ 51513.5500248   48821.99364978  53451.63889205  54910.55855153\n",
      "  50405.68166817  56772.90691171  51909.21824137  50516.14893695\n",
      "  55699.80788403  53107.7805515 ]\n",
      "Mean: 52710.9285312\n",
      "Standard deviation: 2414.72717912\n"
     ]
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.3373689651\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for hyperparameter\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "import time\n",
    "start = time.time()\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "print (time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64366.5544508 {u'max_features': 2, u'n_estimators': 3}\n",
      "55860.1394313 {u'max_features': 2, u'n_estimators': 10}\n",
      "53482.8325596 {u'max_features': 2, u'n_estimators': 30}\n",
      "61320.6172102 {u'max_features': 4, u'n_estimators': 3}\n",
      "53834.6661703 {u'max_features': 4, u'n_estimators': 10}\n",
      "51273.2598733 {u'max_features': 4, u'n_estimators': 30}\n",
      "59851.1600773 {u'max_features': 6, u'n_estimators': 3}\n",
      "53108.4926792 {u'max_features': 6, u'n_estimators': 10}\n",
      "50804.4906775 {u'max_features': 6, u'n_estimators': 30}\n",
      "59225.2197785 {u'max_features': 8, u'n_estimators': 3}\n",
      "52883.782581 {u'max_features': 8, u'n_estimators': 10}\n",
      "50942.1591379 {u'max_features': 8, u'n_estimators': 30}\n",
      "62861.6587799 {u'max_features': 2, u'n_estimators': 3, u'bootstrap': False}\n",
      "54433.8753015 {u'max_features': 2, u'n_estimators': 10, u'bootstrap': False}\n",
      "61043.9509518 {u'max_features': 3, u'n_estimators': 3, u'bootstrap': False}\n",
      "52879.312869 {u'max_features': 3, u'n_estimators': 10, u'bootstrap': False}\n",
      "60252.6537668 {u'max_features': 4, u'n_estimators': 3, u'bootstrap': False}\n",
      "52722.0667582 {u'max_features': 4, u'n_estimators': 10, u'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['std_train_score',\n",
       " 'rank_test_score',\n",
       " 'split4_test_score',\n",
       " u'param_bootstrap',\n",
       " 'split2_train_score',\n",
       " u'param_n_estimators',\n",
       " 'std_score_time',\n",
       " 'split4_train_score',\n",
       " 'split2_test_score',\n",
       " 'mean_score_time',\n",
       " 'mean_fit_time',\n",
       " 'split3_train_score',\n",
       " 'split0_train_score',\n",
       " 'std_test_score',\n",
       " 'split1_train_score',\n",
       " 'split0_test_score',\n",
       " 'mean_test_score',\n",
       " u'param_max_features',\n",
       " 'params',\n",
       " 'std_fit_time',\n",
       " 'split3_test_score',\n",
       " 'mean_train_score',\n",
       " 'split1_test_score']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvres.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 11,  8, 16,  9,  3, 13,  7,  1, 12,  6,  2, 17, 10, 15,  5, 14,\n",
       "        4], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvres['rank_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.24136048955382886, 'median_income'),\n",
       " (0.16197658459849276, u'income_cat'),\n",
       " (0.10882123891274476, 'INLAND'),\n",
       " (0.10627352591969835, u'pop_per_hhold'),\n",
       " (0.067932611343051827, 'longitude'),\n",
       " (0.061828072419167858, 'latitude'),\n",
       " (0.061404514078416045, u'bedrooms_per_room'),\n",
       " (0.053598255849884022, u'rooms_per_hhold'),\n",
       " (0.043339502314388059, 'housing_median_age'),\n",
       " (0.019326989179411204, 'population'),\n",
       " (0.018329155582427956, 'total_bedrooms'),\n",
       " (0.01810170268968371, 'total_rooms'),\n",
       " (0.017836957990116881, 'households'),\n",
       " (0.012235325483341324, '<1H OCEAN'),\n",
       " (0.0050080768169210735, 'NEAR OCEAN'),\n",
       " (0.0025993829445232252, 'NEAR BAY'),\n",
       " (2.7614323902184926e-05, 'ISLAND')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49036.5864272\n"
     ]
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print (final_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datawork]",
   "language": "python",
   "name": "conda-env-datawork-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
